# -*- coding: utf-8 -*-
"""Welcome To Colaboratory

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

import numpy as np

class MarkovDecisionProcess:
    def __init__(self):
        self.states = ["A", "B", "C", "D"]
        self.actions = ["Up", "Down", "Left", "Right"]
        self.rewards = {
            "A": {"Up": -1, "Down": -1, "Left": -1, "Right": -1},
            "B": {"Up": -1, "Down": -1, "Left": -1, "Right": -1},
            "C": {"Up": -1, "Down": -1, "Left": -1, "Right": -1},
            "D": {"Up": -1, "Down": -1, "Left": -1, "Right": 10}
        }
        self.transitions = {
            "A": {"Up": "A", "Down": "B", "Left": "A", "Right": "B"},
            "B": {"Up": "A", "Down": "C", "Left": "B", "Right": "D"},
            "C": {"Up": "B", "Down": "C", "Left": "C", "Right": "C"},
            "D": {"Up": "B", "Down": "D", "Left": "B", "Right": "D"}
        }
        self.current_state = "A"
        self.game_over = False

    def get_available_actions(self):
        """
        Returns a list of available actions for the current state.

        Returns:
            list: Available actions.
        """
        return list(self.transitions[self.current_state].keys())

    def take_action(self, action):
        """
        Takes an action and updates the current state and game status.

        Args:
            action (str): Action to be taken.
        """
        if not self.game_over:
            next_state = self.transitions[self.current_state][action]
            self.current_state = next_state
            reward = self.rewards[self.current_state][action]

            if reward == 10:
                self.game_over = True

            return reward

    def reset(self):
        """
        Resets the game to its initial state.
        """
        self.current_state = "A"
        self.game_over = False

class Agent:
    def __init__(self, mdp, gamma=0.9):
        self.gamma = gamma  # The discount factor
        self.mdp = mdp
        self.total_reward = 0
        self.actions_taken = []

    def play_game(self):
        """
        Plays the game based on the Markov Decision Process until the game is over.
        """
        while not self.mdp.game_over:
            available_actions = self.mdp.get_available_actions()
            action = np.random.choice(available_actions)
            reward = self.mdp.take_action(action)
            self.total_reward += reward
            self.actions_taken.append((self.mdp.current_state, action))

        print("Game over! Total reward: {}".format(self.total_reward))
        print("Actions taken:")
        for state, action in self.actions_taken:
            print("State: {}, Action: {}".format(state, action))

# Create an instance of the MarkovDecisionProcess class
mdp = MarkovDecisionProcess()

# Create an instance of the Agent class
agent = Agent(mdp)

# Play the game
agent.play_game()